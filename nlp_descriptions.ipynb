{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprensión de lenguaje natural para sinopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este *notebook* vamos a probar diversas técnicas de NLP para transformar una sinopsis de un libro en un vector que sirva de input para nuestro posterior modelo del sistema de recomendación. Trataremos de interpretar qué significado tienen esos vectores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeros pasos con spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos, en principio, la librería NLP `spaCy`. En su caso, y como la gran mayoría de sinopsis de los libros de que disponemos son en inglés, utilizaremos el modelo (*pipeline*) `en_core_web_lg`. Hemos escogido la versión grande del modelo puesto que para la transformación de *tokens* de texto en vectores, cuenta con mucha más información precomputada para el cálculo de los mismos, además de ser más efectivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos un primer ejemplo en el que analizamos la sinopsis extraída de *GoodReads* del libro *The Dispossessed*, escrito por Ursula K. Le Guin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shevek False 0.0 True\n",
      ", True 64.72698 False\n",
      "a True 112.98545 False\n",
      "brilliant True 26.414904 False\n",
      "physicist True 38.49606 False\n",
      ", True 64.72698 False\n",
      "decides True 40.19985 False\n",
      "to True 125.107445 False\n",
      "take True 67.411446 False\n",
      "action True 63.787525 False\n",
      ". True 59.90988 False\n",
      "He True 127.80685 False\n",
      "will True 67.574356 False\n",
      "seek True 61.793026 False\n",
      "answers True 41.63712 False\n",
      ", True 64.72698 False\n",
      "question True 45.032265 False\n",
      "the True 72.329216 False\n",
      "unquestionable True 28.41399 False\n",
      ", True 64.72698 False\n",
      "and True 60.75837 False\n",
      "attempt True 47.164364 False\n",
      "to True 125.107445 False\n",
      "tear True 54.97283 False\n",
      "down True 69.28324 False\n",
      "the True 72.329216 False\n",
      "walls True 58.260063 False\n",
      "of True 120.9016 False\n",
      "hatred True 40.90178 False\n",
      "that True 57.417362 False\n",
      "have True 61.392063 False\n",
      "isolated True 40.373966 False\n",
      "his True 95.241104 False\n",
      "planet True 48.34115 False\n",
      "of True 120.9016 False\n",
      "anarchists True 33.042927 False\n",
      "from True 58.585716 False\n",
      "the True 72.329216 False\n",
      "rest True 48.85173 False\n",
      "of True 120.9016 False\n",
      "the True 72.329216 False\n",
      "civilized True 34.164444 False\n",
      "universe True 39.737484 False\n",
      ". True 59.90988 False\n",
      "To True 133.06912 False\n",
      "do True 100.40049 False\n",
      "this True 52.201168 False\n",
      "dangerous True 35.062016 False\n",
      "task True 65.15456 False\n",
      "will True 67.574356 False\n",
      "mean True 49.85471 False\n",
      "giving True 45.396137 False\n",
      "up True 134.42572 False\n",
      "his True 95.241104 False\n",
      "family True 50.043434 False\n",
      "and True 60.75837 False\n",
      "possibly True 31.051395 False\n",
      "his True 95.241104 False\n",
      "life True 68.47362 False\n",
      "— True 83.75058 False\n",
      "Shevek False 0.0 True\n",
      "must True 62.737747 False\n",
      "make True 68.87055 False\n",
      "the True 72.329216 False\n",
      "unprecedented True 29.440308 False\n",
      "journey True 42.88771 False\n",
      "to True 125.107445 False\n",
      "the True 72.329216 False\n",
      "utopian True 29.769533 False\n",
      "mother True 51.1081 False\n",
      "planet True 48.34115 False\n",
      ", True 64.72698 False\n",
      "Urras False 0.0 True\n",
      ", True 64.72698 False\n",
      "to True 125.107445 False\n",
      "challenge True 35.982586 False\n",
      "the True 72.329216 False\n",
      "complex True 49.899117 False\n",
      "structures True 46.460964 False\n",
      "of True 120.9016 False\n",
      "life True 68.47362 False\n",
      "and True 60.75837 False\n",
      "living True 50.483475 False\n",
      ", True 64.72698 False\n",
      "and True 60.75837 False\n",
      "ignite True 35.630524 False\n",
      "the True 72.329216 False\n",
      "fires True 56.129726 False\n",
      "of True 120.9016 False\n",
      "change True 53.024895 False\n",
      ". True 59.90988 False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "\n",
    "# Lee la sinopsis de un libro\n",
    "with open(os.path.join(\"summaries\", \"dispossessed.txt\"), \"r\") as f:\n",
    "    dispossessed_summary = f.read()\n",
    "\n",
    "# Carga el modelo de spacy y tokeniza la sinopsis\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "dispossessed_tokens = nlp(dispossessed_summary)\n",
    "\n",
    "# Imprime información sobre cada token y el potencial vector asociado\n",
    "for token in dispossessed_tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, la gran mayoría de *tokens* tienen un vector asociado, del que incluimos su norma L2 (la norma euclídea). Es llamativo cómo el primer *token*, referente a la palabra *Shevek*, no tiene información sobre un vector. Como indica el atributo `is_oov` (*out of vocabulary*), no es una palabra reconocible dentro del idioma inglés. Es lógico, pues se trata del protagonista de la novela, el cual procede de un planeta de otro sistema solar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comparar también entre dos textos según su similitud. En este ejemplo, incluimos también la sinopsis del libro *The Moon is a harsh mistress*, de Robert A. Heinlein. Ambos libros comparten temas como sociedades utópicas, sistemas alternativos y reflexiones sobre la revolución, además de desarrollarse en lugares típicos de la ciencia ficción como pueden ser la luna o un planeta imaginario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9282042345295354\n"
     ]
    }
   ],
   "source": [
    "# Lee la sinopsis del segundo libro\n",
    "with open(os.path.join(\"summaries\", \"harsh_mistress.txt\"), \"r\") as f:\n",
    "    harsh_mistress_summary = f.read()\n",
    "\n",
    "# Tokeniza la sinopsis\n",
    "harsh_mistress_tokens = nlp(harsh_mistress_summary)\n",
    "\n",
    "# Calcula la similitud entre las sinopsis\n",
    "print(dispossessed_tokens.similarity(harsh_mistress_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según la documentación de `spaCy`, para obtener la similitud se computa un vector de medias para cada uno de los textos a ser comparados. Así, el orden en que aparezcan las palabras dentro del texto no influye en el resultado. \n",
    "\n",
    "Además, dos textos que hablen de lo mismo pero que empleen palabras muy diferentes podrían tener un grado de similitud bajo. Por el contrario, si dos textos no necesariamente parecidos en contenido sí cuentan con una redacción similar, esto es, comparten un número importante de palabras, pueden obtener un grado de similitud elevado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comparar con una sinopsis de un libro de temática diferente para comprobar de nuevo esta métrica. Por ejemplo, probemos con *Wuthering Heights*, de Emily Brontë."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8808053112027434\n"
     ]
    }
   ],
   "source": [
    "# Lee la sinopsis del tercer libro\n",
    "with open(os.path.join(\"summaries\", \"wuthering.txt\"), \"r\") as f:\n",
    "    wuthering_summary = f.read()\n",
    "\n",
    "# Tokeniza la sinopsis\n",
    "wuthering_tokens = nlp(wuthering_summary)\n",
    "\n",
    "# Calcula la similitud entre las sinopsis\n",
    "print(dispossessed_tokens.similarity(wuthering_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La similitud sigue siendo bastante alta a pesar de lo diferentes que son los libros en cuanto a su contenido. \n",
    "\n",
    "Por tanto, podemos deducir que no sólo nos hace falta una representación vectorial \"plana\" de aquellas palabras que aparecen en una sinopsis de un libro en particular, sino que tendremos que aplicar técnicas algo más sofisticadas para dotar de significado a los textos y convertirlos en vectores que se adecuen más al contenido de estos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings (Word2Vec, GloVe, BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg_info",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
