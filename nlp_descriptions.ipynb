{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprensión de lenguaje natural para sinopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este *notebook* vamos a probar diversas técnicas de NLP para transformar una sinopsis de un libro en un vector que sirva de input para nuestro posterior modelo del sistema de recomendación. Trataremos de interpretar qué significado tienen esos vectores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeros pasos con spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos, en principio, la librería NLP `spaCy`. En su caso, y como la gran mayoría de sinopsis de los libros de que disponemos son en inglés, utilizaremos el modelo (*pipeline*) `en_core_web_lg`. Hemos escogido la versión grande del modelo puesto que para la transformación de *tokens* de texto en vectores, cuenta con mucha más información precomputada para el cálculo de los mismos, además de ser más efectivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos un primer ejemplo en el que analizamos la sinopsis extraída de *GoodReads* del libro *The Dispossessed*, escrito por Ursula K. Le Guin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shevek False 0.0 True\n",
      ", True 64.72698 False\n",
      "a True 112.98545 False\n",
      "brilliant True 26.414904 False\n",
      "physicist True 38.49606 False\n",
      ", True 64.72698 False\n",
      "decides True 40.19985 False\n",
      "to True 125.107445 False\n",
      "take True 67.411446 False\n",
      "action True 63.787525 False\n",
      ". True 59.90988 False\n",
      "He True 127.80685 False\n",
      "will True 67.574356 False\n",
      "seek True 61.793026 False\n",
      "answers True 41.63712 False\n",
      ", True 64.72698 False\n",
      "question True 45.032265 False\n",
      "the True 72.329216 False\n",
      "unquestionable True 28.41399 False\n",
      ", True 64.72698 False\n",
      "and True 60.75837 False\n",
      "attempt True 47.164364 False\n",
      "to True 125.107445 False\n",
      "tear True 54.97283 False\n",
      "down True 69.28324 False\n",
      "the True 72.329216 False\n",
      "walls True 58.260063 False\n",
      "of True 120.9016 False\n",
      "hatred True 40.90178 False\n",
      "that True 57.417362 False\n",
      "have True 61.392063 False\n",
      "isolated True 40.373966 False\n",
      "his True 95.241104 False\n",
      "planet True 48.34115 False\n",
      "of True 120.9016 False\n",
      "anarchists True 33.042927 False\n",
      "from True 58.585716 False\n",
      "the True 72.329216 False\n",
      "rest True 48.85173 False\n",
      "of True 120.9016 False\n",
      "the True 72.329216 False\n",
      "civilized True 34.164444 False\n",
      "universe True 39.737484 False\n",
      ". True 59.90988 False\n",
      "To True 133.06912 False\n",
      "do True 100.40049 False\n",
      "this True 52.201168 False\n",
      "dangerous True 35.062016 False\n",
      "task True 65.15456 False\n",
      "will True 67.574356 False\n",
      "mean True 49.85471 False\n",
      "giving True 45.396137 False\n",
      "up True 134.42572 False\n",
      "his True 95.241104 False\n",
      "family True 50.043434 False\n",
      "and True 60.75837 False\n",
      "possibly True 31.051395 False\n",
      "his True 95.241104 False\n",
      "life True 68.47362 False\n",
      "— True 83.75058 False\n",
      "Shevek False 0.0 True\n",
      "must True 62.737747 False\n",
      "make True 68.87055 False\n",
      "the True 72.329216 False\n",
      "unprecedented True 29.440308 False\n",
      "journey True 42.88771 False\n",
      "to True 125.107445 False\n",
      "the True 72.329216 False\n",
      "utopian True 29.769533 False\n",
      "mother True 51.1081 False\n",
      "planet True 48.34115 False\n",
      ", True 64.72698 False\n",
      "Urras False 0.0 True\n",
      ", True 64.72698 False\n",
      "to True 125.107445 False\n",
      "challenge True 35.982586 False\n",
      "the True 72.329216 False\n",
      "complex True 49.899117 False\n",
      "structures True 46.460964 False\n",
      "of True 120.9016 False\n",
      "life True 68.47362 False\n",
      "and True 60.75837 False\n",
      "living True 50.483475 False\n",
      ", True 64.72698 False\n",
      "and True 60.75837 False\n",
      "ignite True 35.630524 False\n",
      "the True 72.329216 False\n",
      "fires True 56.129726 False\n",
      "of True 120.9016 False\n",
      "change True 53.024895 False\n",
      ". True 59.90988 False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "\n",
    "# Lee la sinopsis de un libro\n",
    "with open(os.path.join(\"summaries\", \"dispossessed.txt\"), \"r\") as f:\n",
    "    dispossessed_summary = f.read()\n",
    "\n",
    "# Carga el modelo de spacy y tokeniza la sinopsis\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "dispossessed_tokens = nlp(dispossessed_summary)\n",
    "\n",
    "# Imprime información sobre cada token y el potencial vector asociado\n",
    "for token in dispossessed_tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, la gran mayoría de *tokens* tienen un vector asociado, del que incluimos su norma L2 (la norma euclídea). Es llamativo cómo el primer *token*, referente a la palabra *Shevek*, no tiene información sobre un vector. Como indica el atributo `is_oov` (*out of vocabulary*), no es una palabra reconocible dentro del idioma inglés. Es lógico, pues se trata del protagonista de la novela, el cual procede de un planeta de otro sistema solar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comparar también entre dos textos según su similitud. En este ejemplo, incluimos también la sinopsis del libro *The Moon is a harsh mistress*, de Robert A. Heinlein. Ambos libros comparten temas como sociedades utópicas, sistemas alternativos y reflexiones sobre la revolución, además de desarrollarse en lugares típicos de la ciencia ficción como pueden ser la luna o un planeta imaginario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9282042345295354\n"
     ]
    }
   ],
   "source": [
    "# Lee la sinopsis del segundo libro\n",
    "with open(os.path.join(\"summaries\", \"harsh_mistress.txt\"), \"r\") as f:\n",
    "    harsh_mistress_summary = f.read()\n",
    "\n",
    "# Tokeniza la sinopsis\n",
    "harsh_mistress_tokens = nlp(harsh_mistress_summary)\n",
    "\n",
    "# Calcula la similitud entre las sinopsis\n",
    "print(dispossessed_tokens.similarity(harsh_mistress_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según la documentación de `spaCy`, para obtener la similitud se computa un vector de medias para cada uno de los textos a ser comparados. Así, el orden en que aparezcan las palabras dentro del texto no influye en el resultado. \n",
    "\n",
    "Además, dos textos que hablen de lo mismo pero que empleen palabras muy diferentes podrían tener un grado de similitud bajo. Por el contrario, si dos textos no necesariamente parecidos en contenido sí cuentan con una redacción similar, esto es, comparten un número importante de palabras, pueden obtener un grado de similitud elevado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comparar con una sinopsis de un libro de temática diferente para comprobar de nuevo esta métrica. Por ejemplo, probemos con *Wuthering Heights*, de Emily Brontë."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8808053112027434\n",
      "0.9473500192848667\n"
     ]
    }
   ],
   "source": [
    "# Lee la sinopsis del tercer libro\n",
    "with open(os.path.join(\"summaries\", \"wuthering.txt\"), \"r\") as f:\n",
    "    wuthering_summary = f.read()\n",
    "\n",
    "# Tokeniza la sinopsis\n",
    "wuthering_tokens = nlp(wuthering_summary)\n",
    "\n",
    "# Calcula la similitud entre las sinopsis\n",
    "print(dispossessed_tokens.similarity(wuthering_tokens))\n",
    "print(harsh_mistress_tokens.similarity(wuthering_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La similitud sigue siendo bastante alta a pesar de lo diferentes que son los libros en cuanto a su contenido. \n",
    "\n",
    "Por tanto, podemos deducir que no sólo nos hace falta una representación vectorial \"plana\" de aquellas palabras que aparecen en una sinopsis de un libro en particular, sino que tendremos que aplicar técnicas algo más sofisticadas para dotar de significado a los textos y convertirlos en vectores que se adecuen más al contenido de estos. Esto es, actuar sobre la semántica de frases y textos cortos como un todo en el que el contexto y la semántica son tenidos en cuenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con SBERT, estado del arte para transformación de oraciones en vectores de alta dimensión. Probaremos con varios de los modelos ya entrenados disponibles en la librería `sentence-transformers`. \n",
    "\n",
    "Con esto, podremos calcular la similitud entre dos textos mediante la similitud coseno, tratando a cada uno de nuestros textos como vectores de un espacio euclídeo de dimensión elevada (el coseno del ángulo entre estos vectores nos dará una idea de la semejanza según su dirección y sentido)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7992377877235413\n",
      "0.4220314919948578\n",
      "0.4273483455181122\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el modelo BERT pre-entrenado\n",
    "bert_model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "# Codificamos las sinopsis en vectores (embeddings en un único tensor)\n",
    "book_summaries = [dispossessed_summary, harsh_mistress_summary, wuthering_summary]\n",
    "encoded_book_summaries = bert_model.encode(book_summaries, convert_to_tensor=True)\n",
    "\n",
    "def pretty_print_embeddings(embeddings, labels):\n",
    "    \"\"\"\n",
    "    Imprime los embeddings de cada libro\n",
    "    \"\"\"\n",
    "    for i, embedding in enumerate(np.array(embeddings).tolist()):\n",
    "        print(\"Libro: {}\".format(labels[i]))\n",
    "        print(\"Tamaño del embedding: {}\".format(len(embedding)))\n",
    "        embedding_snippet = \", \".join((str(x) for x in embedding[:3]))\n",
    "        print(\"Embedding: [{}, ...]\\n\".format(embedding_snippet))\n",
    "\n",
    "# Representación de los embeddings\n",
    "titles = ['The Dispossessed', 'The Moon is a Harsh Mistress', 'Wuthering Heights']\n",
    "pretty_print_embeddings(encoded_book_summaries, titles)\n",
    "\n",
    "# Calculamos la similitud entre las sinopsis (matriz de cosine similarity)\n",
    "print(util.cos_sim(encoded_book_summaries, encoded_book_summaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una representación más visual, podemos considerar un gráfico de calor que muestre la matriz de similitudes. Se usa la librería `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_similarity(features, labels, rotation, similarity):\n",
    "    \"\"\"\n",
    "    Representa la similitud entre embeddings con un mapa de calor\n",
    "    \"\"\"\n",
    "    corr = similarity(features, features)\n",
    "    print(corr)\n",
    "    sns.set(font_scale=1.2)\n",
    "    g = sns.heatmap(\n",
    "        corr,\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        cmap=\"YlOrRd\"\n",
    "    )\n",
    "    g.set_xticklabels(labels, rotation=rotation)\n",
    "    g.set_title(\"Similitud semántica entre sinopsis\")\n",
    "\n",
    "plot_similarity(encoded_book_summaries, titles, 90, util.cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Versión del anterior menos potente, pero mucho más rápida\n",
    "Embeddings de 384 dimensiones y normalizados\n",
    "\"\"\"\n",
    "bert_model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "# Codificamos las sinopsis en vectores (embeddings en un único tensor)\n",
    "encoded_book_summaries = bert_model.encode(book_summaries, convert_to_tensor=True)\n",
    "\n",
    "# Representación de los embeddings\n",
    "pretty_print_embeddings(encoded_book_summaries, titles)\n",
    "\n",
    "# Se usa producto escalar al estar los embeddings normalizados\n",
    "plot_similarity(encoded_book_summaries, titles, 90, util.dot_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Segundo modelo más potente\n",
    "768 dimensiones, embeddings normalizados\n",
    "\"\"\"\n",
    "bert_model = SentenceTransformer('all-distilroberta-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Modelo más potente\n",
    "768 dimensiones, embeddings normalizados\n",
    "\"\"\"\n",
    "bert_model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro modelo actual para comparación de texto es USE (*Universal Sentence Encoder*), de Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings (Word2Vec, GloVe, BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg_info",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
