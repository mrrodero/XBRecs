{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos para sistema recomendador proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este *notebook* prepararemos los datos necesarios para evaluar un sistema recomendador externo con la librería `Elliot`. Se usarán los datasets de libros, usuarios y ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de datasets de entrenamiento, validación y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de ratings: 5515602\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta de datasets procesados\n",
    "ready_path = os.path.join(os.getcwd(), \"../..\", \"datasets\", \"ready\")\n",
    "\n",
    "# Lectura del dataset de ratings procesado\n",
    "col_types = {\n",
    "    'user_id': 'int32',\n",
    "    'book_id': 'int32',\n",
    "    'rating': 'float32',\n",
    "}\n",
    "ratings_df = pd.read_csv(ready_path + \"/ratings.csv\", dtype=col_types)\n",
    "print(\"# de ratings:\", ratings_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de libros: 9467\n"
     ]
    }
   ],
   "source": [
    "# Ruta de datasets en bruto\n",
    "raw_path = os.path.join(os.getcwd(), \"../..\", \"datasets\", \"raw\")\n",
    "\n",
    "# Lectura del dataset de libros en bruto (coincidirá con el procesado después de limpiarlo)\n",
    "books_df = pd.DataFrame(pd.read_pickle(raw_path + \"/books_raw.pkl\"))\n",
    "print(\"# de libros:\", books_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de usuarios: 52371\n"
     ]
    }
   ],
   "source": [
    "# IDs de usuarios\n",
    "user_ids = ratings_df['user_id'].unique()\n",
    "print(\"# de usuarios:\", len(user_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a la gran cantidad de usuarios, seleccionamos 10000 de ellos aleatoriamente para un entrenamiento más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de usuarios: 10000\n"
     ]
    }
   ],
   "source": [
    "# Selección de num_users usuarios aleatorios\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "num_users = 10000\n",
    "user_ids_reduced = random.sample(list(user_ids), num_users)\n",
    "print(\"# de usuarios:\", len(user_ids_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, el número de transacciones será más reducido, si bien lo suficientemente representativo, para el cómputo de las métricas de evaluación del sistema recomendador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de ratings: 1053374\n"
     ]
    }
   ],
   "source": [
    "ratings_reduced_df = ratings_df[ratings_df['user_id'].isin(user_ids_reduced)]\n",
    "print(\"# de ratings:\", ratings_reduced_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el dataset de ratings en parte de entrenamiento y parte de test, en una proporción del 80% y 20%, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de ratings en train (train + validation): 842699\n",
      "# de ratings en test: 210675\n"
     ]
    }
   ],
   "source": [
    "# Creamos los datasets de train (80%) y test (20%)\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "train, test = model_selection.train_test_split(ratings_reduced_df, test_size=0.2, random_state=42)\n",
    "print(\"# de ratings en train (train + validation):\", train.shape[0])\n",
    "print(\"# de ratings en test:\", test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, en vista de modelos futuros, el dataset de entrenamiento será parte entrenamiento (70% del global) y parte validación (10% del global). Es fácil comprobar que se debe hacer un split local del dataset de entrenamiento en un 87.5% para entrenamiento *per se* y un 12.5% para validación, consiguiendo los porcentajes globales deseados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de ratings en train: 737361\n",
      "# de ratings en validation: 105338\n"
     ]
    }
   ],
   "source": [
    "# Creamos los datasets de train (87.5% -> 70% del global) y validación (12.5% -> 10% del global)\n",
    "train_train, train_valid = model_selection.train_test_split(train, test_size=0.125, random_state=42)\n",
    "print(\"# de ratings en train:\", train_train.shape[0])\n",
    "print(\"# de ratings en validation:\", train_valid.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a calcular la matriz de similitudes entre los libros del dataset. Para ello, necesitamos crear una función de similitud. Como tanto los libros como los perfiles de usuario cuentan con los mismos atributos (`semantic_sbert`, `semantic_use` y `sentiment`) la función de similitud podrá utilizarse para comparar libros con libros, usuarios con usuarios o libros con usuarios (y viceversa). En este caso, nos interesará para ver la similitud entre libros.\n",
    "\n",
    "La fórmula propuesta es la siguiente: $$S(x, y) = w * S_C(x_{sem}, y_{sem}) + (1 - w) * S_C(x_{sent}, y_{sent}),$$ donde $w \\in [0, 1]$ es un peso para la ponderación entre la parte semántica y la parte de sentiment analysis y $S_C$ es la similitud coseno entre los vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definimos la función de similitud entre dos objetos\n",
    "def sem_sent_sim(item1, item2, sem_option='semantic_sbert', sem_w=0.8) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la similitud entre un objeto y otro.\n",
    "    Los objetos deben tener un vector `'semantic'` y otro `'sentiment'`, \n",
    "    previamente normalizados.\n",
    "\n",
    "    La similitud sigue la siguiente fórmula:\n",
    "\n",
    "    sim(item1, item2) = sem_w * cos_sim(item1[sem_option], item2[sem_option]) + \n",
    "    (1 - sem_w) * cos_sim(item1['sentiment'], item2['sentiment'])\n",
    "\n",
    "    ## Parámetros:\n",
    "    - item1: Primer objeto.\n",
    "    - item2: Segundo objeto.\n",
    "    - sem_option: Opción de contenido semántico. Por defecto su valor\n",
    "    es `'semantic_sbert'` (modelo SBERT), pero también puede valer `'semantic_use'`\n",
    "    (modelo USE).\n",
    "    - sem_w: Peso del contenido semántico. Por defecto su valor es 0.8.\n",
    "\n",
    "    ## Retorna:\n",
    "    La similitud entre ambos objetos.\n",
    "    \"\"\"\n",
    "    # Obtenemos el campo semántico de cada objeto\n",
    "    sem1 = item1[sem_option]\n",
    "    sem2 = item2[sem_option]\n",
    "    # Obtenemos el campo de sentimiento de cada objeto\n",
    "    sent1 = item1['sentiment']\n",
    "    sent2 = item2['sentiment']\n",
    "    # Calculamos la similitud\n",
    "    return sem_w * np.dot(sem1, sem2) + (1 - sem_w) * np.dot(sent1, sent2)\n",
    "\n",
    "def sem_sent_dist(item1, item2, sem_option='semantic_sbert', sem_w=0.8) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la distancia entre un objeto y otro.\n",
    "\n",
    "    Los objetos deben tener un vector 'semantic' y otro 'sentiment', \n",
    "    previamente normalizados.\n",
    "\n",
    "    La similitud sigue la siguiente fórmula:\n",
    "\n",
    "    dist(item1, item2) = 1 - sim(item1, item2)\n",
    "\n",
    "    ## Parámetros:\n",
    "    - item1: Primer objeto.\n",
    "    - item2: Segundo objeto.\n",
    "    - sem_option: Opción de contenido semántico. Por defecto su valor\n",
    "    es `'semantic_sbert'` (modelo SBERT), pero también puede valer `'semantic_use'`\n",
    "    (modelo USE).\n",
    "    - sem_w: Peso del contenido semántico. Por defecto su valor es 0.8.\n",
    "\n",
    "    ## Retorna:\n",
    "    La distancia entre ambos objetos.\n",
    "    \"\"\"\n",
    "    return 1 - sem_sent_sim(item1, item2, sem_option, sem_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_matrix(items, sem_option='semantic_sbert', sem_w=0.8):\n",
    "    \"\"\"\n",
    "    Calcula la matriz de similitud entre los objetos de un dataset.\n",
    "    \n",
    "    ## Parámetros:\n",
    "    - items: Dataset de objetos.\n",
    "    - sem_option: Opción de contenido semántico. Por defecto su valor\n",
    "    es `'semantic_sbert'` (modelo SBERT), pero también puede valer `'semantic_use'`\n",
    "    (modelo USE).\n",
    "    - sem_w: Peso del contenido semántico. Por defecto su valor es 0.8.\n",
    "    \n",
    "    ## Retorna:\n",
    "    La matriz de similitud entre los objetos del dataset.\n",
    "    \"\"\"\n",
    "    num_items = items.shape[0]\n",
    "    matrix = np.zeros((num_items, num_items))\n",
    "\n",
    "    for i in range(num_items):\n",
    "        for j in range(num_items):\n",
    "            item1 = items.iloc[i]\n",
    "            item2 = items.iloc[j]\n",
    "            matrix[i, j] = sem_sent_sim(item1, item2, sem_option, sem_w)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def matrix_to_df(matrix, items, item_id='book_id'):\n",
    "    \"\"\"\n",
    "    Convierte una matriz de similitud en un dataframe.\n",
    "    \n",
    "    ## Parámetros:\n",
    "    - matrix: Matriz de similitud.\n",
    "    - items: Dataset de objetos.\n",
    "    - item_id: Nombre de la columna que contiene el ID de cada objeto.\n",
    "    \n",
    "    ## Retorna:\n",
    "    Un dataframe con la matriz de similitud.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(matrix, index=items[item_id], columns=items[item_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo para 4 libros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999999  0.61621011 0.70077719 0.71809572]\n",
      " [0.61621011 1.0000001  0.52647183 0.46321196]\n",
      " [0.70077719 0.52647183 1.00000019 0.7246611 ]\n",
      " [0.71809572 0.46321196 0.7246611  1.0000001 ]]\n"
     ]
    }
   ],
   "source": [
    "book_ids = [1, 12, 17, 20]\n",
    "books = books_df[books_df['book_id'].isin(book_ids)]\n",
    "similarity_matrix = sim_matrix(books, sem_w=0.8)\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>book_id</th>\n",
       "      <th>1</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.700777</td>\n",
       "      <td>0.526472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.718096</td>\n",
       "      <td>0.463212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "book_id        1         12\n",
       "book_id                    \n",
       "17       0.700777  0.526472\n",
       "20       0.718096  0.463212"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df = matrix_to_df(similarity_matrix, books)\n",
    "similarity_df.loc[[17, 20], [1, 12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de similitud entre libros\n",
    "similarity_matrix = sim_matrix(books_df, sem_w=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>book_id</th>\n",
       "      <th>1</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.700777</td>\n",
       "      <td>0.526472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.718096</td>\n",
       "      <td>0.463212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "book_id        1         12\n",
       "book_id                    \n",
       "17       0.700777  0.526472\n",
       "20       0.718096  0.463212"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df = matrix_to_df(similarity_matrix, books_df)\n",
    "similarity_df.loc[[17, 20], [1, 12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos la matriz de similitud para uso futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda la matriz de similitud\n",
    "similarity_df.to_csv(ready_path + \"/book_similarity.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos cargar la matriz directamente desde la siguiente celda sin necesidad de calcularla de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>9963</th>\n",
       "      <th>9965</th>\n",
       "      <th>9968</th>\n",
       "      <th>9969</th>\n",
       "      <th>9971</th>\n",
       "      <th>9973</th>\n",
       "      <th>9982</th>\n",
       "      <th>9985</th>\n",
       "      <th>9987</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.700777</td>\n",
       "      <td>0.318825</td>\n",
       "      <td>0.193065</td>\n",
       "      <td>0.160345</td>\n",
       "      <td>0.228328</td>\n",
       "      <td>0.237620</td>\n",
       "      <td>0.346737</td>\n",
       "      <td>0.288061</td>\n",
       "      <td>0.263016</td>\n",
       "      <td>0.526472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380829</td>\n",
       "      <td>0.225062</td>\n",
       "      <td>0.254349</td>\n",
       "      <td>0.184396</td>\n",
       "      <td>0.479671</td>\n",
       "      <td>0.479671</td>\n",
       "      <td>0.469189</td>\n",
       "      <td>0.191034</td>\n",
       "      <td>0.525387</td>\n",
       "      <td>0.247396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.718096</td>\n",
       "      <td>0.285862</td>\n",
       "      <td>0.131382</td>\n",
       "      <td>0.216830</td>\n",
       "      <td>0.209667</td>\n",
       "      <td>0.235295</td>\n",
       "      <td>0.350952</td>\n",
       "      <td>0.246060</td>\n",
       "      <td>0.281529</td>\n",
       "      <td>0.463212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338160</td>\n",
       "      <td>0.273511</td>\n",
       "      <td>0.206503</td>\n",
       "      <td>0.176313</td>\n",
       "      <td>0.422291</td>\n",
       "      <td>0.422291</td>\n",
       "      <td>0.413554</td>\n",
       "      <td>0.245042</td>\n",
       "      <td>0.444242</td>\n",
       "      <td>0.252896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 9467 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                1         2         3         4         6         7         8  \\\n",
       "book_id                                                                         \n",
       "17       0.700777  0.318825  0.193065  0.160345  0.228328  0.237620  0.346737   \n",
       "20       0.718096  0.285862  0.131382  0.216830  0.209667  0.235295  0.350952   \n",
       "\n",
       "                9        11        12  ...      9963      9965      9968  \\\n",
       "book_id                                ...                                 \n",
       "17       0.288061  0.263016  0.526472  ...  0.380829  0.225062  0.254349   \n",
       "20       0.246060  0.281529  0.463212  ...  0.338160  0.273511  0.206503   \n",
       "\n",
       "             9969      9971      9973      9982      9985      9987     10000  \n",
       "book_id                                                                        \n",
       "17       0.184396  0.479671  0.479671  0.469189  0.191034  0.525387  0.247396  \n",
       "20       0.176313  0.422291  0.422291  0.413554  0.245042  0.444242  0.252896  \n",
       "\n",
       "[2 rows x 9467 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load similarity matrix\n",
    "similarity_df = pd.read_csv(ready_path + \"/book_similarity.csv\", index_col=0, dtype='float32')\n",
    "similarity_df.index = similarity_df.index.astype('int16')\n",
    "similarity_df.loc[[17, 20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recomendaciones del modelo (vector de similitudes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las recomendaciones, nos basaremos en el historial de valoraciones de cada usuario. Se seleccionará, por cada usuario, una lista de libros que haya valorado positivamente. Esto es, con un rating mayor o igual que 0.75. Luego, con la matriz de similitudes se obtendrá la submatriz correspondiente a dichos libros y, teniendo en cuenta el rating, se calculará una suma por cada uno de los libros del dataset de dichas similitudes. De esta forma se obtendrá un vector de similitudes suma, del cual se escogerán aquellos libros con los $k$ valores mayores.\n",
    "\n",
    "Si representamos dicha submatriz como\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "S_{j_1;1} & S_{j_1;2} & \\ldots & S_{j_1;N}\\\\\n",
    "S_{j_2;1} & S_{j_2;2} & \\ldots & S_{j_2;N} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "S_{j_l;1} & S_{j_l;2} & \\ldots & S_{j_l;N}\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "donde $j_1, \\ldots, j_l$ son los índices de los libros que ha valorado positivamente el usuario, el vector resultante es\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\sum\\limits_{i=1}^{l}r_{j_i}S_{j_i;1}, & \\sum\\limits_{i=1}^{l}r_{j_i}S_{j_i;2}, & \\ldots, & \\sum\\limits_{i=1}^{l}r_{j_i}S_{j_i;N}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Finalmente, se toman los libros que se correspondan con las $k$ coordenadas mayores de este vector. Nos referimos con $r_{j_i}$ a la valoración (positiva) que el usuario ha dado al libro $j_i$ para $i \\in \\{1, \\ldots, l\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        8       13    0.75\n",
       "1        8       14    1.00\n",
       "2        8       28    0.75\n",
       "3        8       43    0.25\n",
       "4        8       45    0.50"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el dataframe de entrenamiento para el modelo a partir del dataset de train\n",
    "train_df = pd.DataFrame(train, columns=['user_id', 'book_id', 'rating'])\n",
    "train_df.sort_values(by=['user_id', 'book_id'], inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de usuarios: 10000\n"
     ]
    }
   ],
   "source": [
    "# Creamos un dataframe con los usuarios que aparecen en el dataset de train\n",
    "users_df = pd.DataFrame(columns=['user_id'])\n",
    "users_df['user_id'] = train_df['user_id'].unique()\n",
    "users_df.sort_values(by=['user_id'], inplace=True)\n",
    "users_df.reset_index(drop=True, inplace=True)\n",
    "print(\"# de usuarios:\", users_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# de libros: 9467\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos la información de los libros que han sido valorados por los usuarios del dataset de train\n",
    "books_df = books_df[books_df['book_id'].isin(train_df['book_id'].unique())]\n",
    "books_df.sort_values(by=['book_id'], inplace=True)\n",
    "books_df.reset_index(drop=True, inplace=True)\n",
    "print(\"# de libros:\", books_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest(user_id: int, sim_matrix: pd.DataFrame, train_df: pd.DataFrame, books_df: pd.DataFrame, k=10):\n",
    "    \"\"\"\n",
    "    Calcula los k libros más cercanos a un usuario.\n",
    "\n",
    "    ## Parámetros:\n",
    "    - user_id: ID del usuario del que queremos obtener los k libros más cercanos.\n",
    "    - sim_matrix: Matriz de similitud entre libros.\n",
    "    - train_df: `DataFrame` del dataset de entrenamiento.\n",
    "    - books_df: `DataFrame` de libros en el dataset de entrenamiento.\n",
    "    - k: Número de vecinos más cercanos que queremos obtener. Por defecto\n",
    "    su valor es 10.\n",
    "\n",
    "    ## Retorna:\n",
    "    k tuplas (book_id, similitud) con los k vecinos más cercanos al objeto.\n",
    "    \"\"\"\n",
    "    def sim_vector(sim_matrix: pd.DataFrame, user_likes: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Calcula el vector de similitudes para los libros respecto de un usuario.\n",
    "\n",
    "        ## Parámetros:\n",
    "        - sim_matrix: Matriz de similitud entre libros.\n",
    "        - user_likes: `DataFrame` de los libros que le gustan al usuario\n",
    "        en el dataset de entrenamiento.\n",
    "\n",
    "        ## Retorna:\n",
    "        Vector con las similitudes suma.\n",
    "        \"\"\"\n",
    "        sub_matrix = sim_matrix.loc[user_likes['book_id']]\n",
    "        pond_sub_matrix = sub_matrix * user_likes['rating'].values.reshape(-1, 1)\n",
    "        return np.sum(pond_sub_matrix, axis=0)\n",
    "    \n",
    "    # Ratings positivas del usuario\n",
    "    user_ratings = train_df[train_df['user_id'] == user_id]\n",
    "    user_likes = user_ratings[user_ratings['rating'] >= 0.75]\n",
    "    sim_vec = sim_vector(sim_matrix, user_likes)\n",
    "    nearest = list(zip(sim_matrix.index, sim_vec))\n",
    "    # Quitar de la lista los libros que ya le gustan al usuario\n",
    "    nearest = [x for x in nearest if x[0] not in user_ratings['book_id'].values]\n",
    "    # Obtenemos los k vecinos más cercanos\n",
    "    nearest.sort(key=lambda x: x[1], reverse=True)\n",
    "    return nearest[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo para el usuario con identificador 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3134, 18.33085823059082),\n",
       " (4769, 17.717296600341797),\n",
       " (1123, 17.69397735595703),\n",
       " (2953, 17.66826057434082),\n",
       " (6769, 17.596405029296875),\n",
       " (7384, 17.589773178100586),\n",
       " (689, 17.49903678894043),\n",
       " (2679, 17.470413208007812),\n",
       " (5734, 17.467529296875),\n",
       " (9216, 17.45812225341797)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_nearest(8, similarity_df, train_df, books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos los k libros más similares a cada usuario (sin contar los ya positivamente valorados)\n",
    "k = 50\n",
    "predictions_df = users_df.copy()\n",
    "predictions_df['nearest'] = predictions_df['user_id'].apply(lambda x: k_nearest(x, similarity_df, train_df, books_df, k=k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>nearest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>[(3134, 18.33085823059082), (4769, 17.71729660...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>[(3134, 28.66318702697754), (3962, 28.39384651...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>[(9216, 17.394306182861328), (7731, 17.1793060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>[(692, 27.253429412841797), (8785, 27.03939437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>[(3134, 29.49867057800293), (2088, 28.55392265...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                            nearest\n",
       "0        8  [(3134, 18.33085823059082), (4769, 17.71729660...\n",
       "1       13  [(3134, 28.66318702697754), (3962, 28.39384651...\n",
       "2       14  [(9216, 17.394306182861328), (7731, 17.1793060...\n",
       "3       20  [(692, 27.253429412841797), (8785, 27.03939437...\n",
       "4       28  [(3134, 29.49867057800293), (2088, 28.55392265..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos la columna 'nearest' en dos columnas: 'book_id' y 'prediction'\n",
    "predictions_df = predictions_df.explode('nearest')\n",
    "predictions_df[['book_id', 'prediction']] = pd.DataFrame(predictions_df['nearest'].tolist(), index=predictions_df.index)\n",
    "predictions_df = predictions_df.drop('nearest', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>3134</td>\n",
       "      <td>18.330858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>4769</td>\n",
       "      <td>17.717297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1123</td>\n",
       "      <td>17.693977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2953</td>\n",
       "      <td>17.668261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>6769</td>\n",
       "      <td>17.596405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  prediction\n",
       "0        8     3134   18.330858\n",
       "0        8     4769   17.717297\n",
       "0        8     1123   17.693977\n",
       "0        8     2953   17.668261\n",
       "0        8     6769   17.596405"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de los ficheros para Elliot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez calculadas todas las predicciones de los libros por usuario a partir del modelo, guardaremos las propias predicciones en formato .tsv, de tal forma que puedan ser utilizadas en `Elliot` como `ProxyRecommender`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de datasets de entrenamiento\n",
    "training_path = os.path.join(os.getcwd(), \"../..\", \"datasets\", \"training\")\n",
    "# Guardamos el dataset de predicciones así como los de entrenamiento, test y validación\n",
    "predictions_df.to_csv(training_path + \"/predictions/predictions_cb.tsv\", sep='\\t', header=None, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg_info",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
